# Unsplash Multimodality Search

An end to end project that builds Multimodality Search Solution for Unsplash Lite Dataset.

When you combined the textual and image features together in same vector space the search results are more relevant and natural language freindly.

See the demo for youself to see the difference between traditional search results and multi modality search results. 

I compare the results from this demo with search results from https://unsplash.com and with Google Image Search.

TIP: Instead of trying just simple generic keywords, try full sentences like "*Woman Smelling Gardenia Flower*" or "*A person about to jump from mountain top*"


[![Unsplash Multi Modality Search]({https://github.com/pankajarm/unsplash_multimodality_search/blob/main/a_person_about_to_jump_from_mountain_top.png})]({https://github.com/pankajarm/unsplash_multimodality_search/blob/main/MultiModal-UnSplash-Lite-Demo_720.mov})


Try Yourself here:

**[Unsplash Lite MultiModality Search Demo](http://unsplash-lite-front-http-lb-927462080.us-west-2.elb.amazonaws.com)**

Please star the repo if you like this project.

Credits:

* Unsplash Lite Dataset Team [https://github.com/unsplash/datasets](https://github.com/unsplash/datasets)

* JINA Team [https://jina.ai/](https://jina.ai/)

* Streamlit Team [https://streamlit.io/](https://streamlit.io/)


The detail blog post coming soon....
