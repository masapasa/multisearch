{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bfcf784",
   "metadata": {},
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c465db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finetuner\n",
    "from docarray import DocumentArray, Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# login with same credentials which you used to push private dataset to jina cloud\n",
    "# for public dataset just use any login\n",
    "finetuner.notebook_login(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e3f145",
   "metadata": {},
   "source": [
    "### Finetune Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuner.notebook_login()\n",
    "run_name = 'unsplash-lite-clip-run-onnx-11132022-2145'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a23c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = finetuner.get_run(run.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b924c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = finetuner.fit(\n",
    "    model='openai/clip-vit-base-patch32',\n",
    "    train_data='unsplash-lite-clean-train-data-clip',\n",
    "    eval_data='unsplash-lite-clean-eval-data-clip',\n",
    "    run_name=run_name,\n",
    "    epochs=5,\n",
    "    learning_rate= 1e-7,\n",
    "    loss='CLIPLoss',\n",
    "    device='cuda',\n",
    "    to_onnx=True,#MAKE SURE TO CHOOSE FOR ONNX\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, the fine-tuning might takes many hours\n",
    "for entry in run.stream_logs():\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d89601",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = finetuner.get_run(run.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e604da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, the fine-tuning might takes many hours\n",
    "for entry in run.stream_logs():\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb02a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_name = 'unsplash-lite-clean-clip-onnx-model'\n",
    "artifact = run.save_artifact(artifact_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c895723",
   "metadata": {},
   "source": [
    "##### Quick Check Downloaded aritifact for Inference with ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_local_path = f\"{artifact_name}/{run_name}.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d52c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_da = DocumentArray([Document(text='some text to encode')])\n",
    "image_da = DocumentArray([Document(uri='https://upload.wikimedia.org/wikipedia/commons/4/4e/Single_apple.png')])\n",
    "\n",
    "clip_text_encoder = finetuner.get_model(artifact=artifact_local_path, select_model='clip-text', is_onnx=True)\n",
    "clip_image_encoder = finetuner.get_model(artifact=artifact_local_path, select_model='clip-vision', is_onnx=True)\n",
    "\n",
    "finetuner.encode(model=clip_text_encoder, data=text_da)\n",
    "finetuner.encode(model=clip_image_encoder, data=image_da)\n",
    "\n",
    "print(text_da.embeddings.shape)\n",
    "print(image_da.embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_da.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea0f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_da.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec40e1",
   "metadata": {},
   "source": [
    "##### For Backend Server to run your FineTuned Onnx model on Clip Server\n",
    "* Make sure finetuned_clip.yml exist in backend directory\n",
    "* create a new directory for unsplash-finetuned-onnx\n",
    "* unzip the unsplash-lite-clip-run-onnx-11132022-2145.zip\n",
    "* go to models/clip-text and copy models.onnx as textual.onnx to new unsplash-finetuned-onnx directory\n",
    "* go to models/clip-vision and copy models.onnx as visual.onnx to new unsplash-finetuned-onnx directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f7f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
