{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a596d72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aswin/anaconda3/envs/fast/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import requests\n",
    "from docarray import DocumentArray\n",
    "from docarray import dataclass\n",
    "from docarray.typing import Image, Text\n",
    "from docarray import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd233ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore unsplash dataset, if needed all csv files\n",
    "\n",
    "path = '/home/aswin/data/unsplash-research-dataset-lite-latest/'\n",
    "documents = ['photos', 'colors']\n",
    "datasets = {}\n",
    "\n",
    "for doc in documents:\n",
    "    files = glob.glob(path + doc + \".tsv*\")\n",
    "    \n",
    "    subsets = []\n",
    "    for filename in files:\n",
    "        df = pd.read_csv(filename, sep='\\t', header=0)\n",
    "        subsets.append(df)\n",
    "    \n",
    "    datasets[doc] = pd.concat(subsets, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d67716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "photo_id                              0\n",
       "photo_url                             0\n",
       "photo_image_url                       0\n",
       "photo_submitted_at                    0\n",
       "photo_featured                        0\n",
       "photo_width                           0\n",
       "photo_height                          0\n",
       "photo_aspect_ratio                    0\n",
       "photo_description                 14098\n",
       "photographer_username                 0\n",
       "photographer_first_name               0\n",
       "photographer_last_name             1582\n",
       "exif_camera_make                   2812\n",
       "exif_camera_model                  2852\n",
       "exif_iso                           3192\n",
       "exif_aperture_value                3600\n",
       "exif_focal_length                  3503\n",
       "exif_exposure_time                 3215\n",
       "photo_location_name               15309\n",
       "photo_location_latitude           17853\n",
       "photo_location_longitude          17856\n",
       "photo_location_country            16211\n",
       "photo_location_city               18856\n",
       "stats_views                           0\n",
       "stats_downloads                       0\n",
       "ai_description                     1359\n",
       "ai_primary_landmark_name          23813\n",
       "ai_primary_landmark_latitude      23813\n",
       "ai_primary_landmark_longitude     23813\n",
       "ai_primary_landmark_confidence    23813\n",
       "blur_hash                            11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['photos'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8929c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets['photos'].dropna(axis=0, subset=['ai_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef74e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75184c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "photo_id                              0\n",
       "photo_url                             0\n",
       "photo_image_url                       0\n",
       "photo_submitted_at                    0\n",
       "photo_featured                        0\n",
       "photo_width                           0\n",
       "photo_height                          0\n",
       "photo_aspect_ratio                    0\n",
       "photo_description                 13325\n",
       "photographer_username                 0\n",
       "photographer_first_name               0\n",
       "photographer_last_name             1472\n",
       "exif_camera_make                   2631\n",
       "exif_camera_model                  2668\n",
       "exif_iso                           2984\n",
       "exif_aperture_value                3371\n",
       "exif_focal_length                  3281\n",
       "exif_exposure_time                 3008\n",
       "photo_location_name               14457\n",
       "photo_location_latitude           16824\n",
       "photo_location_longitude          16827\n",
       "photo_location_country            15302\n",
       "photo_location_city               17807\n",
       "stats_views                           0\n",
       "stats_downloads                       0\n",
       "ai_description                        0\n",
       "ai_primary_landmark_name          22491\n",
       "ai_primary_landmark_latitude      22491\n",
       "ai_primary_landmark_longitude     22491\n",
       "ai_primary_landmark_confidence    22491\n",
       "blur_hash                            11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d046891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23641\n"
     ]
    }
   ],
   "source": [
    "# get unique photo id's\n",
    "photo_id_list = list(set(df['photo_id'].values))\n",
    "print(len(photo_id_list))\n",
    "# photo_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0bb5ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23641\n"
     ]
    }
   ],
   "source": [
    "photo_image_url_list = list(set(df['photo_image_url'].values))\n",
    "print(len(photo_image_url_list))\n",
    "# photo_image_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7637091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23641\n"
     ]
    }
   ],
   "source": [
    "photo_id_to_img_url_dict = {}\n",
    "\n",
    "photo_id_to_img_url_dict = dict(zip(df.photo_id, df.photo_image_url))\n",
    "print(len(photo_id_to_img_url_dict))\n",
    "# photo_id_to_img_url_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c38cb36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsplash_lite_img_emb_da = DocumentArray()\n",
    "\n",
    "for photo_id in photo_id_list:\n",
    "    try:\n",
    "        image_path = f'resize_images/{photo_id}.jpg'\n",
    "        doc = Document(uri=image_path).load_uri_to_image_tensor()\n",
    "        unsplash_lite_img_emb_da.append(doc)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6c40f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────── Documents Summary ────────────────╮\n",
       "│                                                  │\n",
       "│   Type                   DocumentArrayInMemory   │\n",
       "│   Length                 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                       │\n",
       "│   Homogenous Documents   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>                   │\n",
       "│   Multimodal dataclass   <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>                    │\n",
       "│                                                  │\n",
       "╰──────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────── Documents Summary ────────────────╮\n",
       "│                                                  │\n",
       "│   Type                   DocumentArrayInMemory   │\n",
       "│   Length                 \u001b[1;36m0\u001b[0m                       │\n",
       "│   Homogenous Documents   \u001b[3;91mFalse\u001b[0m                   │\n",
       "│   Multimodal dataclass   \u001b[3;92mTrue\u001b[0m                    │\n",
       "│                                                  │\n",
       "╰──────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unsplash_lite_img_emb_da.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3064924",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m unsplash_lite_img_emb_da[\u001b[39m0\u001b[39;49m]\n",
      "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/docarray/array/mixins/getitem.py:52\u001b[0m, in \u001b[0;36mGetItemMixin.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\n\u001b[1;32m     49\u001b[0m     \u001b[39mself\u001b[39m, index: \u001b[39m'\u001b[39m\u001b[39mDocumentArrayIndexType\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     50\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[\u001b[39m'\u001b[39m\u001b[39mDocument\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDocumentArray\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     51\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(index, (\u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mgeneric)) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(index, \u001b[39mbool\u001b[39m):\n\u001b[0;32m---> 52\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_doc_by_offset(\u001b[39mint\u001b[39;49m(index))\n\u001b[1;32m     53\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(index, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     54\u001b[0m         is_access_path \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m@\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/docarray/array/storage/memory/getsetdel.py:57\u001b[0m, in \u001b[0;36mGetSetDelMixin._get_doc_by_offset\u001b[0;34m(self, offset)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_doc_by_offset\u001b[39m(\u001b[39mself\u001b[39m, offset: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDocument\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data[offset]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "unsplash_lite_img_emb_da[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ddb806",
   "metadata": {},
   "source": [
    "### Embedding Creation by Model Inference  with ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "104628ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'unsplash-lite-clip-run-onnx-11132022-2145'\n",
    "artifact_name = 'unsplash-lite-clean-clip-onnx-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0280036",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_local_path = f\"{artifact_name}/{run_name}.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe1bcc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finetuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65d52c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 15:39:40.882775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-18 15:39:41.625517: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-18 15:39:41.907831: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-18 15:39:44.669831: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-18 15:39:44.670222: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-18 15:39:44.670244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/aswin/anaconda3/envs/fast/lib/python3.9/site-packages/finetuner/__init__.py:439: RuntimeWarning: You are using cuda device for ONNX inference, please considercalling `pip install onnxruntime-gpu` to speed up inference.\n",
      "  warnings.warn(\n",
      "Please report this session_id: [yellow bold]d9f071ce-674e-11ed-8261-00155dea2c3e[/] to https://github.com/jina-ai/jina-hubble-sdk/issues\n"
     ]
    },
    {
     "ename": "ArtifactNotFound",
     "evalue": "Artifact unsplash-lite-clean-clip-onnx-model/unsplash-lite-clip-run-onnx-11132022-2145.zip not found, details: 40001: ParamValidationError: 40001",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParamValidationError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/_finetuner/models/load.py:67\u001b[0m, in \u001b[0;36m_pull_remote_artifact\u001b[0;34m(artifact_id, token)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     _ \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mdownload_artifact(\u001b[39mid\u001b[39;49m\u001b[39m=\u001b[39;49martifact_id, f\u001b[39m=\u001b[39;49mzbuffer)\n\u001b[1;32m     68\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/hubble/client/client.py:170\u001b[0m, in \u001b[0;36mClient.download_artifact\u001b[0;34m(self, id, f, show_progress)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39m# first get download uri.\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_request(\n\u001b[1;32m    171\u001b[0m     url\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_base_url \u001b[39m+\u001b[39;49m EndpointsV2\u001b[39m.\u001b[39;49mdownload_artifact,\n\u001b[1;32m    172\u001b[0m     data\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mid\u001b[39;49m},\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    175\u001b[0m \u001b[39m# Second download artifact.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/hubble/client/base.py:106\u001b[0m, in \u001b[0;36mBaseClient.handle_request\u001b[0;34m(self, url, method, data, files, headers, json, log_error)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39merror(\n\u001b[1;32m    103\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPlease report this session_id: [yellow bold]\u001b[39m\u001b[39m{\u001b[39;00msession_id\u001b[39m}\u001b[39;00m\u001b[39m[/] \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    104\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mto https://github.com/jina-ai/jina-hubble-sdk/issues\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    105\u001b[0m         )\n\u001b[0;32m--> 106\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/hubble/client/base.py:96\u001b[0m, in \u001b[0;36mBaseClient.handle_request\u001b[0;34m(self, url, method, data, files, headers, json, log_error)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m400\u001b[39m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_error_request(resp)\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jsonify:\n",
      "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/hubble/client/base.py:53\u001b[0m, in \u001b[0;36mBaseClient._handle_error_request\u001b[0;34m(self, resp)\u001b[0m\n\u001b[1;32m     51\u001b[0m ExceptionCls \u001b[39m=\u001b[39m errorcodes[code]\n\u001b[0;32m---> 53\u001b[0m \u001b[39mraise\u001b[39;00m ExceptionCls(response\u001b[39m=\u001b[39mresp, data\u001b[39m=\u001b[39mdata, message\u001b[39m=\u001b[39mmessage, code\u001b[39m=\u001b[39mcode)\n",
      "\u001b[0;31mParamValidationError\u001b[0m: 40001: ParamValidationError: 40001",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArtifactNotFound\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Quick Test\u001b[39;00m\n\u001b[1;32m      2\u001b[0m image_da \u001b[39m=\u001b[39m DocumentArray([Document(uri\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://upload.wikimedia.org/wikipedia/commons/4/4e/Single_apple.png\u001b[39m\u001b[39m'\u001b[39m)])\n\u001b[0;32m----> 4\u001b[0m clip_image_encoder \u001b[39m=\u001b[39m finetuner\u001b[39m.\u001b[39;49mget_model(artifact\u001b[39m=\u001b[39;49martifact_local_path, select_model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mclip-vision\u001b[39;49m\u001b[39m'\u001b[39;49m, is_onnx\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      6\u001b[0m finetuner\u001b[39m.\u001b[39mencode(model\u001b[39m=\u001b[39mclip_image_encoder, data\u001b[39m=\u001b[39mimage_da)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(image_da\u001b[39m.\u001b[39msummary())\n",
      "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/finetuner/__init__.py:445\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(artifact, token, batch_size, select_model, device, logging_level, is_onnx)\u001b[0m\n\u001b[1;32m    439\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    440\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mYou are using cuda device for ONNX inference, please consider\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcalling `pip install onnxruntime-gpu` to speed up inference.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    442\u001b[0m         category\u001b[39m=\u001b[39m\u001b[39mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    443\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m is_onnx:\n\u001b[0;32m--> 445\u001b[0m     inference_engine \u001b[39m=\u001b[39m ONNXRuntimeInferenceEngine(\n\u001b[1;32m    446\u001b[0m         artifact\u001b[39m=\u001b[39;49martifact,\n\u001b[1;32m    447\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    448\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    449\u001b[0m         select_model\u001b[39m=\u001b[39;49mselect_model,\n\u001b[1;32m    450\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    451\u001b[0m         logging_level\u001b[39m=\u001b[39;49mlogging_level,\n\u001b[1;32m    452\u001b[0m     )\n\u001b[1;32m    453\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     inference_engine \u001b[39m=\u001b[39m TorchInferenceEngine(\n\u001b[1;32m    455\u001b[0m         artifact\u001b[39m=\u001b[39martifact,\n\u001b[1;32m    456\u001b[0m         token\u001b[39m=\u001b[39mtoken,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    460\u001b[0m         logging_level\u001b[39m=\u001b[39mlogging_level,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/_finetuner/models/inference.py:509\u001b[0m, in \u001b[0;36mONNXRuntimeInferenceEngine.__init__\u001b[0;34m(self, artifact, is_onnx, token, batch_size, select_model, device, device_id, omp_num_threads, intra_op_num_threads, inter_op_num_threads, logging_level, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    457\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    458\u001b[0m     artifact: Union[\u001b[39mstr\u001b[39m, RunnerModel, RunArtifact],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    470\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m    The finetuner inferencer can load any model trained with Finetuner and use it to\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m    encode Documents. Alternatively, a pre-trained model in the compatible finetuner format\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[39m        options.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    510\u001b[0m         artifact\u001b[39m=\u001b[39;49martifact,\n\u001b[1;32m    511\u001b[0m         is_onnx\u001b[39m=\u001b[39;49mis_onnx,\n\u001b[1;32m    512\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    513\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    514\u001b[0m         select_model\u001b[39m=\u001b[39;49mselect_model,\n\u001b[1;32m    515\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    516\u001b[0m         device_id\u001b[39m=\u001b[39;49mdevice_id,\n\u001b[1;32m    517\u001b[0m         logging_level\u001b[39m=\u001b[39;49mlogging_level,\n\u001b[1;32m    518\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    519\u001b[0m     )\n\u001b[1;32m    521\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_omp_num_threads \u001b[39m=\u001b[39m omp_num_threads\n\u001b[1;32m    522\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intra_op_num_threads \u001b[39m=\u001b[39m intra_op_num_threads\n",
      "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/_finetuner/models/inference.py:111\u001b[0m, in \u001b[0;36mInferenceEngine.__init__\u001b[0;34m(self, artifact, is_onnx, token, batch_size, select_model, device, device_id, logging_level, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDevice ID set to [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device_id\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    110\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBatch size set to [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_size\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_artifact \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_artifact(artifact)\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_metadata()\n\u001b[1;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_data_pipeline()\n",
      "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/_finetuner/models/inference.py:135\u001b[0m, in \u001b[0;36mInferenceEngine._load_artifact\u001b[0;34m(self, artifact)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(artifact, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    134\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mArtifact as path set to [\u001b[39m\u001b[39m{\u001b[39;00martifact\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_dump \u001b[39m=\u001b[39m load_artifact(\n\u001b[1;32m    136\u001b[0m         artifact\u001b[39m=\u001b[39;49martifact,\n\u001b[1;32m    137\u001b[0m         is_onnx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_is_onnx,\n\u001b[1;32m    138\u001b[0m         select_model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_select_model,\n\u001b[1;32m    139\u001b[0m         token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_token,\n\u001b[1;32m    140\u001b[0m     )\n\u001b[1;32m    142\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(artifact, RunArtifact):\n\u001b[1;32m    143\u001b[0m     models \u001b[39m=\u001b[39m artifact\u001b[39m.\u001b[39mmodels\n",
      "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/_finetuner/models/load.py:138\u001b[0m, in \u001b[0;36mload_artifact\u001b[0;34m(artifact, is_onnx, select_model, token)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPulling from Jina AI Cloud: \u001b[39m\u001b[39m{\u001b[39;00martifact\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m         zbuffer \u001b[39m=\u001b[39m _pull_remote_artifact(artifact, token)\n\u001b[1;32m    140\u001b[0m     _models2buffers \u001b[39m=\u001b[39m _load_artifact_from_zipfile(artifact, zbuffer, export_type)\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(_models2buffers) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/fast/lib/python3.9/site-packages/_finetuner/models/load.py:69\u001b[0m, in \u001b[0;36m_pull_remote_artifact\u001b[0;34m(artifact_id, token)\u001b[0m\n\u001b[1;32m     67\u001b[0m     _ \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mdownload_artifact(\u001b[39mid\u001b[39m\u001b[39m=\u001b[39martifact_id, f\u001b[39m=\u001b[39mzbuffer)\n\u001b[1;32m     68\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m---> 69\u001b[0m     \u001b[39mraise\u001b[39;00m ArtifactNotFound(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mArtifact \u001b[39m\u001b[39m{\u001b[39;00martifact_id\u001b[39m}\u001b[39;00m\u001b[39m not found, details: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(exc)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[39mreturn\u001b[39;00m zbuffer\n",
      "\u001b[0;31mArtifactNotFound\u001b[0m: Artifact unsplash-lite-clean-clip-onnx-model/unsplash-lite-clip-run-onnx-11132022-2145.zip not found, details: 40001: ParamValidationError: 40001"
     ]
    }
   ],
   "source": [
    "# Quick Test\n",
    "image_da = DocumentArray([Document(uri='https://upload.wikimedia.org/wikipedia/commons/4/4e/Single_apple.png')])\n",
    "\n",
    "clip_image_encoder = finetuner.get_model(artifact=artifact_local_path, select_model='clip-vision', is_onnx=True)\n",
    "\n",
    "finetuner.encode(model=clip_image_encoder, data=image_da)\n",
    "\n",
    "print(image_da.summary())\n",
    "print(image_da.embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040bc7e1",
   "metadata": {},
   "source": [
    "##### FillUp unsplash_lite_img_da with Embeddings created by our finetuned CLIP Image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4cb75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuner.encode(model=clip_image_encoder, data=unsplash_lite_img_emb_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42abb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsplash_lite_img_emb_da.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f301d2d9",
   "metadata": {},
   "source": [
    "##### remove all tensors to decrease the size of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28366d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all tensors to decrease the size of embeddings\n",
    "del unsplash_lite_img_emb_da[:, 'tensor']\n",
    "\n",
    "unsplash_lite_img_emb_da.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe29d6",
   "metadata": {},
   "source": [
    "#### Convert local URI to Online URI, so we can show images directly from Online "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94597f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in unsplash_lite_img_emb_da:\n",
    "    try:\n",
    "#         print(\"original:\", doc.uri)\n",
    "        photo_id = str(str(doc.uri).split('/')[1]).split('.')[0]\n",
    "#         print(\"photo_id:\",photo_id)\n",
    "#         print(\"photo_image_url:\", photo_id_to_img_url_dict[photo_id])\n",
    "        doc.uri = photo_id_to_img_url_dict[photo_id]\n",
    "#         src_uri_unsplash_lite_emb_da.append(doc)\n",
    "    except:\n",
    "        print(\"couldn't convert=>\", doc.uri)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f4726",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsplash_lite_img_emb_da.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsplash_lite_img_emb_da[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b1a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsplash_lite_img_emb_da.save_binary(\"../frontend/unsplash_lite_img_emb_da.bin\", compress='lz4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e6dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_da = DocumentArray.load_binary(\"../frontend/unsplash_lite_img_emb_da.bin\", compress='lz4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc2236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "91cf809ebeac7834cab322c0e9393d8c235d5aedcc8b94bfe1d55e7236ca8197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
